
# Sign Language Detector

## Overview

Sign Language Detector is a Python project that utilizes computer vision and deep learning techniques to accurately detect and decode sign language gestures in video sequences. This project employs key point detection and LSTM (Long Short-Term Memory) deep learning models to achieve a high accuracy rate in recognizing sign language gestures.

## Technologies Used

- Python
- Jupyter Notebooks
- OpenCV
- LSTM (Long Short-Term Memory)

## Key Features

- **Key Point Detection Model**: The project incorporates a key point detection model that accurately identifies and tracks over 20 points on faces, arms, and hands in video sequences. This model is implemented using the mediapipe collection in OpenCV.
  
- **LSTM Deep Learning**: The project implements LSTM deep learning architecture, trained on a sign language dataset. 

## Acknowledgments

Special thanks to [mediapipe](https://google.github.io/mediapipe/) for their key point detection tools and the contributors of the sign language datasets used for training the LSTM model.
